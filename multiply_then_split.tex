
% \subsection{The naive algorithm}

Let \(f\) be a homogeneous polynomial of degree \(n\) 
in \(S\), 
so that \(Z(f)\) is a Calabi-Yau hypersurface.
Recall from Subsection \ref{subsec:split:frob} that
\(\mathfrak{m}^{[p]} = (x_{1}^{p}, \ldots, x_{n}^{p})\)
is the Frobenius power of the maximal ideal \((x_1,..,x_n)\).
Following \cite{kty-2022-fedder}, we have the following
algorithm to calculate the quasi-\(F\)-split height.

\begin{algorithm}[H]
% I think consistency of the term overrides title capitalization.
\caption{quasi-\(F\)-split height: naive algorithm}
\label{alg:qfs:naive}
\KwInput{
	Chosen bound $b \in \mathbb{N}$, \\
	~~~~~~~~~~~~~Homogeneous polynomial $f \in S$ of degree $n$
}
\KwOutput{$h(f)$}
$g \gets f^{p - 1}$\;
\If{$g \notin \mathfrak{m}^{[p]}$}{
	\Return $1$\;
}
$\Delta \gets \Delta_1(f^{p-1})$\;
$h \gets 2$\;
\While{true}{
	\If{$b < h$}{
		\Return $\infty$\;
	}
	$g \gets u(\Delta g)$\;
	\If{$g \notin \mathfrak{m}^{[p]}$}{
		\Return $h$\;
	}
	$h \gets h + 1$\;
}
\end{algorithm}

\begin{thm}
	[\cite{kty-2022-fedder}, Theorem C]
	Assume that
	\(Z(f)\) has quasi-\(F\)-split height \(h < b\).
	Then Algorithm \ref{alg:qfs:naive} terminates
	and returns \(h\).
\end{thm}

\begin{proof}
	This is just rephrasing \cite[Theorem~C]{kty-2022-fedder}.
\end{proof}

In the case of Calabi-Yau hypersurfaces, we have bounds on the height by
\cite{van-der-geer-katsura-2003-calabi-yau},
so we can deterministically recover the height.  
See also \cite[Theorem~0.1]{artin-1974-k3-surfaces},
for the case of K3 surfaces.
For a K3 surface, the height (if finite) is bounded by 10.

\begin{ex}
    Let \(p=3\), and let
    \(f = x^4 + y^4 + z^4 + w^4 \in S = k[x,y,z,w]\).
    Raising \(f\) to the \(p-1 = 2\) in \(\mathbb{F}_{3}\), we get
    \[
    g = x^8 + 2x^4y^4 + 2x^4z^4 + 2x^4w^4 + y^8 + 2y^4z^4 + 2y^4w^4 + z^8 + 2z^4w^4 + w^8
    .\] 
    The only monomial of degree \(8\) that is not contained
    in \(\mathfrak{m}^{[p]} = (x^{3}, y^{3}, z^{3}, w^{3})\) is \(x^{2}y^{2}z^{2}w^{2}\).
    Call this monomial \(c\).
    Since this coefficient of \(c\) in \(g\) is zero, we conclude
    by the classical Fedder's criterion (Theorem \ref{thm:fedder:criterion})
    that \(g\) is not \(F\)-split.
    Next, we must calculate \(\Delta_{1}(g)\).
    To do this, we take a lift of \(g\) by regarding the coefficients
    as being in \(\mathbb{Z}\) instead of \(\mathbb{F}_{3}\).
    We raise \(g^3\) in the integers, and subtract by every term of \(g\) 
    cubed.

    Then, we multiply \(g\) by \(\Delta_{1}(g)\), getting a polynomial of degree 24.
    We apply the splitting of Frobenius, as described in Algorithm \ref{alg:naive:u}, 
    obtaining another polynomial of degree \(8\). 
    We can now check the term \(x^2y^2z^2w^2\) again, and it will again be zero. 
    For this choice of $f$, all of the exponents for all quantities 
    must be multiples of four.\footnote{
    In fact, this implies that the degree \(8\) polynomial is zero.
    However, this phenomenon is quite rare.
    }
    We then continue, multiplying, applying the splitting, checking the coefficient, 
    until we conclude that the height is greater than 10. 
    Now, by Hodge theory, if the height is greater than 10, it must be infinity. 
    So we conclude that the height is infinity.
\end{ex}

\subsection{The key idea: finding the matrix of the linear operator ``multiply then split''}

An implementation of Algorithm \ref{alg:qfs:naive}
is provided in MMPSingularities.jl.
The bottleneck ends up being polynomial multiplication, 
in two places:
\begin{enumerate}[(1)]
    \item raising (a lift of) \(g = f^{p-1}\) to the \(p\)-th power 
        (in line 2 of Algorithm \ref{alg:calc:delta1})
    \item multiplying \(g\) by \(\Delta_{1}(f^{p-1})\) 
        (in line 11 of Algorithm \ref{alg:qfs:naive})
\end{enumerate}

\noindent For a quartic K3 surface of characteristic \(5\),
for example, each step takes about 1 second 
using FLINT \cite{flint-2023-flint}. 

We now explain how to overcome the second
bottleneck. Since \(Z(f)\) is Calabi-Yau
(i.e. \(\deg f = n\)), we have that \(f^{p-1}\) has degree
\(n(p-1)\). 
Furthermore, by Proposition \ref{prop:delta1:formula}
the degree of \(\Delta_{1}(f^{p-1})\) 
is \(np(p - 1)\).
Thus, \(\Delta_{1}(f^{p-1})g\) has degree
\(n(p^{2} - 1)\).
Since the effect 
of \(u\) on any polynomial is subtracting \(p-1\)
from the exponents of the terms and dividing by \(p\) 
(see Algorithm \ref{alg:naive:u}).
Thus, the ``multiply then split'' map 
\(g \mapsto u(\Delta_{1}(f^{p-1}) g)\) 
is a linear map from 
the space of homogeneous polynomials of degree \(n(p-1)\) 
to itself.
As a consequence of this observation,
if we can efficiently compute the matrix of 
\(g \mapsto u(\Delta_{1}(f^{p-1})g)\),
we can repeatedly apply matrix-vector multiplication.

Furthermore, when \(g\) is written as a vector 
in the basis of homogeneous monomials of degree
\(n(p-1)\), we can test if \(g \notin \mathfrak{m}^{[p]}\) 
in an especially simple way: the only 
monomial that is not in \(\mathfrak{m}^{[p]}\) is
\(x_{1}^{p-1}\cdots x_{n}^{p-1}\), 
see for example \cite{kty-2022-fedder}.
Thus, we can check if a single element of the vector representing
\(g\) is nonzero.

The algorithm for Fedder's criterion then becomes:

\begin{algorithm}[H]
\caption{Quasi-\(F\)-split height: matrix-based algorithm}
\label{alg:qfs:matrix}
\KwInput{
	Chosen bound $b \in \mathbb{N}$, \\
	~~~~~~~~~~~~~Homogeneous polynomial $f \in S$ of degree $n$
}
\KwOutput{$h(f)$}
$g \gets f^{p - 1}$\;
\If{$g \notin \mathfrak{m}^{[p]}$}{
	\Return $1$\;
}
$\Delta \gets \Delta_1(f^{p - 1})$\;
$M \gets $ the matrix of $g^{\prime} \mapsto u(\Delta g^{\prime})$\;
$h \gets 2$\;
$g_v \gets $ the representation of $g$ as a vector\;
$i \gets $ the index of the monomial $x_{1}^{p - 1} \dots x_{n}^{p - 1}$\;
\While{true}{
	\If{$b < h$}{
		\Return $\infty$\;
	}
	$g_v \gets Mg_v$\;
	\If{$g_v[i] \neq 0$}{
		\Return $h$\;
	}
	$h \gets h + 1$
}
\end{algorithm}

% Thus, we have reduced our problem (algorithmically, at least)
% to finding the matrix of the ``multiply then split'' operation.

To find the matrix of ``multiply then split''
in the Algorithm for the quasi-\(F\)-split height
of a Calabi-Yau hypersurface, 
we must first multiply all possible 
monomials by \(\Delta_{1}(f)\) 
and then apply the map \(u\).
Here, we consider a slightly more general problem.
As usual, let \(S = k[x_{1}, \ldots, x_{n}]\).
Let $S_\ell$ denote the vector space of homogeneous degree $\ell$ polynomials in \(S\).
We let \(B_{\ell}\) denote a lexicographically-ordered list
of the monomial basis of \(S_{\ell}\).
Fix some \(D \in \mathbb{N}\), and let \(\Delta \in S_D\).
Furthermore, fix \(d \in \mathbb{N}\).
We consider the problem of finding the matrix of 
\(g \mapsto u(\Delta g)\)
on the space \(S_{d}\).
The target of this map is
\(S_{d^{\prime}}\), where
\(d^{\prime} \colonequals \frac{d+D-n-1}{p}\).
By convention, if \(d^{\prime}\) is not an integer,
we declare \(S_{d^{\prime}}\) to be zero.
Note that in this case there are
there are no terms which survive \(u\), so
\(g \mapsto u(\Delta g)\) is indeed the zero map.

\begin{rmk}
    If \(\Delta = \Delta_{1}(f^{p-1})\) and \(d = n(p-1)\),
	as in the case of calculating the quasi-\(F\)-split
	height of a Calabi-Yau hypersurface, 
	then \(d^{\prime} = d\) and the matrix is 
	square.
\end{rmk}

Our first observation is that naively 
multiplying and then applying \(u\) 
as in Algorithm \ref{alg:naive:u}
does plenty of unnecessary work.
In particular, any term in the 
product \(\Delta g\) with exponents 
not congruent to 
\((p-1, \ldots, p-1) \mod p\)
is not needed. 
Even if \(g\) is a monomial, giving a linear
algorithm for multiplication, using naive
multiplication stores a large amount of unnecessary terms
in memory.
Both of our improved algorithms ignore
all of these unnecessary terms.

\begin{defn}
    (c.f. \cite{stanley-1997-enumerative}, pg. 18)
    The \textit{weak integer compositions} of $k$ into $n$ parts, 
    denoted $\wics(k, n)$, is the set of ordered tuples of
    nonnegative integers
	\((d_{1}, \ldots, d_{n})\) such that 
    \(d_{1} + \ldots + d_{n} = k\).
\end{defn}

\begin{ex}
    $\wics(2, 3) = \lbrace (2, 0, 0), (0, 2, 0), (0, 0, 2), (1, 1, 0), (1, 0, 1), (0, 1, 1) \rbrace$.
\end{ex}

Thus, $\wics(d, n)$ generates the exponent tuples of the 
monomial basis of the vector space of $d$-homogeneous 
$n$-variate polynomials over a field $F$.
It follows that the dimension of the vector space is $|\wics(k, n)|$.

\begin{lem}
    \label{lem:wics:size}
    $|\wics(k, n)| = \binom{k + n - 1}{n - 1}$
\end{lem}

\begin{proof}
	This is a classical argument which goes by the 
    name ``sticks and stones,'' ``stars and bars,'' or 
    ``dots and dividers.''
\end{proof}


\begin{rmk}
    The number of terms of \(\Delta\) is bounded 
    above by \(\binom{D+n-1}{n-1}\) by Lemma \ref{lem:wics:size}.
    Likewise, the number of elements of 
    \(B_{d}\) is \(\binom{d+n-1}{n-1}\).
    For all of our algorithmic complexity calculations, 
    we let $\ell_{d} = \length(B_{d}) = \binom{n + d - 1}{n - 1}$, 
    and $\ell_{\Delta} = \length(\Delta) \leq \binom{n + D - 1}{n - 1}$.
    In the case of the quasi-\(F\)-split height of a K3 surface, 
    $\ell_{d} = \binom{n(p - 1) + n - 1}{n - 1} = \binom{np - 1}{n - 1}$, 
    and $\ell_{\Delta} = \binom{np(p - 1) + n - 1}{n - 1} = \binom{n(p^2 - p + 1) - 1}{n - 1}$.
\end{rmk}

\begin{defn}
	Let \(m\) be a monomial in \(S\). 
	Then we say that \(m\) \textit{matches}
	with another monomial \(m^{\prime}\) 
	if the monomial \(mm^{\prime}\) is
	not killed by \(u\).
\end{defn}

Concretely, this means that $\exps(m) + \exps(m^{\prime}) \equiv (p - 1, \dots, p - 1) \mod p$.

\subsection{The trivial algorithm}

\begin{algorithm}[H]
    \caption{Matrix of multiply then split: \triv}
    \label{alg:matrix:trivial}
    \KwInput{
        $\Delta, B_d, B_{d^\prime}, p$
    }
    \KwNotation{Let $\ell_d = \code{length}(B_d), \ell_{d^\prime} = \code{length}(B_{d^\prime})$}
    \KwOutput{$\ell_{d^\prime} \times \ell_d $ matrix representing ``multiply then split''}
    $M \gets \text{zero matrix of size } \ell_{d^\prime} \times \ell_d $\;
    \For{$m \in B_d$}{
        \For{$\delta \in \Delta$}{
            \Comment{If $\delta$ matches with $m$}
            \If{$\code{exps}(\delta) + \code{exps}(m) \equiv (p - 1, \dots, p - 1) \mod p$}{
                \Comment{Apply $u$ to $\delta m$}
                $\text{res} \gets (\code{exps}(\delta) + \code{exps}(m) - (p - 1, \dots, p - 1)) / p$\;
                $\text{row} \gets \code{indexof}(\text{res},B_{d^{\prime}})$\;
                $\text{col} \gets \code{indexof}(m, B_d)$\;
                $M[\text{row}, \text{col}] = \code{coeff}(\delta)$
            }
        }
    }
    \Return $M$
\end{algorithm}

In this algorithm, which we call \triv, we iterate through 
the monomials $m \in B_{d}$, each corresponding to a column in the
resulting matrix. For each monomial, we search for terms 
that match $\delta \in \Delta$, apply $u$ to their product $\delta m$, and 
get the lexicographical index of the result to find which 
row to add to.

In this algorithm, the matrix can be generated in 
$O(\ell_{d}\ell_{\Delta})$ operations. 
This can be
seen from the nested loops, assuming that integer 
arithmetic operations are constant time.

In practice, the majority of the combinations of 
terms of $\Delta$ and $B_{d}$ don't match. This means in
Algorithm \ref{alg:matrix:trivial}, much of our 
runtime is wasted on checking for whether terms match.
However, we emphasize that this algorithm, if 
implemented in parallel on the GPU, is indeed
fast enough to not be a bottleneck in practice.

% \subsection{Modified merge-based algorithm}

% We now introduce an algorithm that utilizes 
% properties of monomial ordering to reduce the 
% number of comparisons 
% performed in checking whether two terms match.


% \begin{cor}
% 	\label{cor:match:order}
% 	Let \(\leq_{lex}\) denote the 
% 	lexicographical ordering.
% 	If \(X \leq_{lex} Y\),
% 	then 
% 	\(m(Y) \leq_{lex} m(X)\).
% \end{cor}

% \begin{proof}
% 	Follows from the definition of lexicographical
% 	ordering.
% \end{proof}

% Using these two corollaries, we have the following algorithm,
% which we call \merge:

% \begin{algorithm}[H]
% \caption{Matrix of multiply then split: \merge}
% \label{alg:theta:merge}
% \KwInput{
%     $\Delta, B_d, B_{d^\prime}, p$
% }
% \KwNotation{Let $\ell_d = \code{length}(B_d), \ell_{d^\prime} = \code{length}(B_{d^\prime})$}
% \KwOutput{$\ell_{d^\prime} \times \ell_d $ matrix representing ``multiply then split''}
% $M \gets \text{zero matrix of size } \ell_{d^\prime} \times \ell_d $\;
% $L \gets [\code{exps}(\delta) \modp ~|~ \delta \in \Delta]$\;
% $R \gets [\code{exps}(m) \modp ~|~ m \in B_{d}]$\;
% \Comment{Lexicographically sort $L$ and $R$ and keep the permutations}
% $P_1 =$ \code{sortperm}\((L)\), $P_2 =$ \code{sortperm}\((R)\) \;
% \Comment{Permute \(\Delta\) and \(B_d\)}
% $\Delta^{\prime} \gets \Delta[P_1], B_d^{\prime} \gets B_d[P_2]$\;
% \(l \gets 1, r \gets \code{length}(R)\)\;
% \While{\(r \geq 1 ~\textnormal{and}~ l \leq \code{length}(L)\)}{
%     cmp \(\gets L[l] + R[r] - (p-1, \ldots, p-1)\)\;
%     \uIf(\tcp*[h]{If lex sum of pair too small, increment index of $L$}){\textnormal{cmp < 0}}{
%         \(l \gets l + 1\)\;
%     }\uElseIf(~\tcp*[h]{If lex sum of pair too big, decrement index of $R$}){\textnormal{cmp > 0}}{
%         \(r \gets r - 1\)\;
%     }\Else(~\tcp*[h]{Match found}){
%         matchr \(\gets R[r]\)\;
%         numLmatches \(\gets\) the number of adjacent entries in \(L\) which are equal to \(L[l]\)\;
%         \Comment{For each monomial of $B_d$}
%         \While{$R[r] ~\code{==}~ \textnormal{matchr} ~\textnormal{and}~ 1 \leq r$}{
%             \Comment{Find matching terms of $\Delta$}
%             \For{\(ll \in \{l, l+1, \ldots, l+\textnormal{numLmatches} - 1\})\)}{
%                 \Comment{And apply $u$}
%                 res \(\gets (\code{exps}(\Delta^{\prime}[ll]) + \code{exps}(B^{\prime}[r]) - (p-1, \ldots, p-1)) / p\)\;
%                 \(\text{col} \gets \code{indexof}(B^{\prime}[r],B_{d})\)\;
%                 \(\text{row} \gets \code{indexof}(\text{res},B_{d^{\prime}})\)\;
%                 \(M[\text{row},\text{col}] = \code{coeff}(\Delta^{\prime}[ll])\)\;
%             }
%             \(r \gets r - 1\)\;
%         }
%         \(l \gets l + \text{numLmatches} - 1\)\;
%     }
% }
% \Return $M$
% \end{algorithm}

% Note that the inner while loops account for the fact that
% after modding by \(p\), one does not expect 
% either array to have unique elements.
% The algorithm is justified by the previous corollaries.

% In practice, instead of sorting the arrays in place, 
% we use a method like Julia's \texttt{sortperm}
% to get the sort permutation.

% Because we perform two sorts, then a linear merge, 
% we perform 
% $\ell_{d} \log \ell_{d} + \ell_{\Delta} \log \ell_{\Delta} + \ell_{d} + \ell_{\Delta}$ operations, 
% giving the algorithm complexity 
% $O(\max(\ell_{d} \log \ell_{d}, \ell_{\Delta} \log \ell_{\Delta}))$.
% In practice (for Calabi-Yau hypersurfaces), 
% the $\ell_{\Delta} \log \ell_{\Delta}$ usually dominates.

\subsection{Weak integer compositions-based algorithm}

\begin{lem}
	\label{lem:tuples:modp}
	Let \(X = (x_{1}, \ldots, x_{n}),
	Y = (y_{1}, \ldots, y_{n})\)
	be in \(\{0, \ldots, p-1\}^{n} \ins \mathbb{Z}^{n}\).
	Then \(X + Y = 
	(p-1, \ldots, p-1) \mod p\)
	if and only if 
	\(X + Y = 
	(p-1, \ldots, p-1)\).
\end{lem}

\begin{proof}
	Each coordinate has \(x_{i} + y_{i} \leq 2(p-1) = 2p-2\).
\end{proof}

\begin{cor}
    \label{cor:unique:match}
	Let $X$ be as above.
	Then there exists a unique
	match \(m(X) \in \{0, \ldots, p-1\}^{n}\).
\end{cor}

\begin{proof}
	\(m(X) = 
	(p-1, \ldots, p-1) - X\).
	The claim follows from 
	\ref{lem:tuples:modp}.
\end{proof}

Essentially, this corollary says that
when we consider the exponent tuple mod $p$ of 
an arbitrary monomial of \(B\),
it has a unique
match mod \(p\).

\begin{lem}
    \label{lem:generate:matching}
    The set of exponent tuples of \(B_{d}\) that match with $\delta$ is given by 
    \[
        \left\{ m(\exps(\delta) \mathmod p) + p\cdot w ~\Big|~ w \in \wics 
        \left(\frac{d - sum(m(\exps(\delta) \mathmod p))}{p}, n \right) \right\}
    \]
    where $sum(X)$ is the sum of the elements of tuple $X$, and $m$ is the matching function from Corollary \ref{cor:unique:match}.
\end{lem}

\begin{proof}
    Direct computation from the definitions of weak integer compositions and matching terms.
\end{proof}


Because this expression is quite convoluted, we 
provide an example of a computation 
that may come up in calculating the quasi-\(F\)-split 
height of a K3 quartic surface over $\mathbb{F}_5$.

\begin{ex}
    Let $p = 5$, \(n = 4\), and $\delta$ a monomial 
    with exponent tuple $(21, 19, 22, 18)$. 
    Then $B_{16}$ is the monomial basis of 
    \(S_{16}\) (over $\mathbb{F}_5$). 
    To find the monomials of $B_{16}$ that match with 
    $\delta$, we begin by reducing $(21, 19, 22, 18) \mathmod 5 = (1, 4, 2, 3)$.
    This makes $m((1, 4, 2, 3)) = (3, 0, 2, 1)$ the 
    exponent tuple of a matching monomial mod \(p\).
    However, \((3, 0, 2, 1)\) isn't in $B_{16}$. 
    For it to be in $B_{16}$, we need to add $16 - (3 + 0 + 2 + 1) = 10$ 
    to the degree, and to maintain congruence to 
    $(4, 4, 4, 4) \mathmod 5$, we need to add two $5$'s 
    to the elements of $(3, 0, 2, 1)$. This corresponds 
    to $\{5w ~|~ w \in \wics(2, 4)\}$, which is:
    \begin{align*}
        \{&(10, 0, 0, 0), (5, 5, 0, 0), (5, 0, 5, 0), (5, 0, 0, 5), (0, 10, 0, 0), \\
        &(0, 5, 5, 0), (0, 5, 0, 5), (0, 0, 10, 0), (0, 0, 5, 5), (0, 0, 0, 10)\}
    \end{align*}
        
    \noindent Adding each of these to $(3, 0, 2, 1)$, we get the 
    exponent tuples of monomials that match with $(21, 19, 22, 18)$:
    \begin{align*}
        \{&(13, 0, 2, 1), (8, 7, 0, 1), (8, 0, 7, 1), (8, 0, 2, 6), (3, 10, 2, 1), \\
        &(3, 5, 7, 1), (3, 5, 2, 6), (3, 0, 12, 1), (3, 0, 7, 6), (3, 0, 2, 11)\}
    \end{align*}    
\end{ex}

Because we need it later for our complexity computations, we have the corollary:

\begin{cor}
    \label{cor:num:matches}
    The number of matching monomials of any term $\delta$ is 
    bounded above by $\binom{\lfloor \frac{d}{p} \rfloor + n - 1}{n - 1}$.
\end{cor}

\begin{proof}
    By Lemma \ref{lem:generate:matching}, there are 
    $\Big |\wics \left(\frac{d - sum(m(\exps(\delta) \mathmod p))}{p}, n \right) \Big |$ 
    monomials that match with $\delta$.
    Because the division is exact, 
    $\lfloor \frac{d}{p} \rfloor \geq \frac{d - sum(m(\exps(\delta) \mathmod p))}{p}$,
    giving the upper bound 
    $|\wics(\lfloor \frac{d}{p} \rfloor, n)| = \binom{\lfloor \frac{d}{p} \rfloor + n - 1}{n - 1}$.
\end{proof}

Denoting the expression from Lemma \ref{lem:generate:matching} 
by \code{generateMatchingMonomials}$(\delta, p, M_d)$, we have
the following algorithm, which we call \wicsalg:

\begin{algorithm}[H]
    \caption{Matrix of multiply then split: \wicsalg}
    \KwInput{$\Delta, B_{d}, B_{d^{\prime}}, p$}
    \KwNotation{Let \(\ell_{d} = \length(B_{d})\), 
    \(\ell_{d^{\prime}} = \length(B_{d^{\prime}})\)}
    \KwOutput{$\ell_{d^{\prime}} \times \ell_{d}$ 
    	matrix representing ``multiply then split''}
    $M \gets \text{zero matrix of size } \ell_{d^\prime} \times \ell_d $\;
    \For{$\delta \in \Delta$}{
        mons $\gets \code{generateMatchingMonomials}(\delta, p, B_{d})$\;
        \For{$m \in \textnormal{mons}$}{
            $\text{col} \gets \code{indexof}(m,B_{d})$\;
			res $\gets (\code{exps}(\delta) + \code{exps}(m) - (p-1, \ldots, p-1)) / p$\;
			$\text{row} \gets \code{indexof}(\text{res},B_{d^{\prime}})$\;
            $M[\text{row}, \text{col}] = \code{coeff}(\delta)$\;
        }
    }
    \Return $M$
    \label{alg:matrix:WICS}
\end{algorithm}

This algorithm 
generates the matrix in 
$O \left( \ell_{\Delta} \cdot \binom{\lfloor \frac{d}{p} \rfloor + n - 1}{n - 1} \right)$ operations.
The number of matching monomials each term $\delta$ 
has is bounded above by $\binom{\lfloor \frac{d}{p} \rfloor + n - 1}{n - 1}$ 
by Corollary \ref{cor:num:matches}, which is 
effectively constant for all reasonably computable $n$ and $p$.

\subsection{Implementation}

In the implementation of \triv ~and \wicsalg, there are a 
few optimizations and considerations common to all the implementations.
First, all exponent tuples are bitpacked into 
unsigned integers, improving memory efficiency 
and allowing for faster comparisons.
Note that a comparison between two unsigned integers 
is the same as a lexicographical comparison between the tuples.
Broadcasted addition and subtraction on bitpacked 
$n$-tuples reduces to addition and subtraction of 
integers, though broadcasted division and modulo still 
require $n$ separate operations.

All algorithms require the \code{indexof}$()$ function, 
which we implement using Julia's \texttt{Dict\{K,V\}}, 
which is implemented as a hash table.

\triv ~and \wicsalg ~are easily GPU-parallelizable by creating 
a thread for each term of $\Delta$, and performing the insides of the loop in each thread.
This creates the problem of needing an \code{indexof}$()$ function, 
since Julia's \texttt{Dict\{K,V\}} is not compatible with the GPU.
The solution we implement is a static hash table, with size 
and hashing function decided at compile time.
Due to Julia's JIT compilation nature, creating this 
hash table is quite slow.
Another solution can be to perform a binary search 
for the \code{indexof}$()$ function, since $B_d$ is lexicographically 
sorted, but for one-off computations, users are better 
off using non-parallelized \wicsalg ~to avoid 
first-time GPU kernel compilation times.
However, if many matrices need to be created, caching 
the hash table allows the GPU implementations to far outpace 
the non-parallelized CPU implementations.

% \merge ~should be parallelizable by implementing a modified parallel merge and using a parallel sort. 
% However, we expect the sorting bottleneck to mean that such a parallel algorithm wouldn't beat GPU-parallel \wicsalg,
% so we don't bother developing the modified parallel merge.

Below in Figure \ref{fig:momts:compare}, we compare running times 
for all the \(p\) which we consider. 
\wicsalg \, ends up being the fastest practically, 
both on the CPU and the GPU.
We did not try running the tests for \triv~ on the 
CPU for \(p=11,13\) because we do not expect 
it to finish in a reasonable
amount of time.

\begin{figure}[ht]
\label{fig:momts:compare}
\begin{center}
\begin{tabular}{c c c c c c}
    \toprule
    p & \triv ~- CPU & \triv ~- GPU %& \merge   
      & \wicsalg ~- CPU & \wicsalg ~- GPU \\
    \midrule
    3 & 0.01   & 0.0007  %& 0.001  
      & 0.001   & 0.0002  \\                                       
    5 & 1.6    & 0.005   %& 0.046  
      & 0.028   & 0.0024  \\
    7 & 45.33  & 0.104   %& 0.670  
      & 0.277   & 0.025  \\
    11 &    -  & 6.796   %& 26.35  
       & 5.45    & 0.56  \\
    13 &    -  & 31.86   %& 88.97  
       & 17.06   & 2.05 \\
    \bottomrule
\end{tabular}
\caption{Comparison of timings for various algorithms that calculate
the matrix of ``multiply then split''. 
Times are in seconds
and are an average of 10 different trials.}
\end{center}
\end{figure}

