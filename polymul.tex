\subsection{Kronecker Substitution and Homogeneity}
In multivariate polynomial arithmetic, it is commonplace to map a multivariate polynomial to a univariate 
polynomial. This is because a comparison between two degree sequences $(d_1, \dots , d_n)$ of monomials 
$x_1^{d_1} \dots x_n^{d_n}$ is $n$ times slower than comparing two integers. One method of doing this is the Kronecker 
substitution:

\begin{defn}
    Let $M$ be a non-inclusive upper bound on the degree of any variable of the polynomial
    $f \in R[x_1, \dots, x_n]$. Then, the Kronecker Substitution produces a univariate polynomial $g \in R[z]$ by substituting powers of $z$ in 
    the evaluation of $f$: [cite this]{https://arxiv.org/pdf/1401.6694}

    \begin{center}
        $g(z) = f(z, z^M, z^{M^2}, \dots, z^{M^{n-1}})$
    \end{center}
\end{defn}

\noindent Additionally, because our polynomials are homogeneous, we can simply ignore one variable in all of our 
operations between monomials of the same degree, since the variable can be recovered by subtracting the 
known total degree of the monomial from the homogeneous degree.

\subsubsection{FFT}

For our algorithms of choice, we chose Monagan's powfps algorithm implemented in FLINT for computing $g = f^{p-1} \; (1)$, and the 
Fast Fourier Transform for computing $g^p \; (3)$. Monagan's powfps algorithm already computes $(1)$ in time 
on the order of milliseconds, so we focus more on the bottleneck, $(3)$. Even though the FFT isn't suited for 
sparse problems, the massive performance boost from GPU parallelization allows it to run faster than other 
algorithms, as discussed in section 3.3.

To determine the size of our FFT, we need to compute the largest possible degree that the Kronecker 
Substitution can map a monomial of $g^p$ to. Let $f \in R[x_1, \dots, x_n]$ be homogeneous with degree $d$. Then, 
$(f^{p-1})^p$ is homogeneous with degree $D = dp(p - 1)$. Then, by Definition 3.1, we can select an upper bound 
of $M = D + 1$, and the maximum degree the Kronecker Substitution will be able to map to is $D*M^{n - 1}$. But 
if we ignore one variable of $f$ due to the homogeneous property, we get a maximum degree of $D*M^{n - 2}$. 
Because we use a radix-2 FFT, we find the next power of 2 after $D*M^{n - 2} + 1$, the $+1$ coming from a 
$k$-length FFT representing a $k-1$ degree polynomial.

Below is a table of FFT lengths needed to compute $g^p$:


\begin{center}
    \textbf{Required FFT lengths to compute $g^p$}
    \begin{tabular}{c|c|c|c|c}
    $\bsfrac{\,p}{n}$ & 5 & 7 & 11 & 13 \\ \hline
    4 & 1,048,576 & 8,388,608 & 134,217,728 & 268,435,456 \\
    5 & 134,217,728 & 2,147,483,648 & 137,438,953,472 & 549,755,813,888
    \end{tabular}
\end{center}    

% To make computing $\Delta_1(f^{p-1})$ even faster, we look for ways to reduce the FFT size. One such way is by imposing restrictions on the space of possible monomials. Consider the restriction where we remove all terms containing only one variable raised to the $n$-th power from the basis of monomials of $f$.

% [Explanation on how the restriction affects kroneckersubstitution]

% Below is a table of FFT lenghts needed to compute the restricted $g^p$:


% \begin{center}
%     \textbf{Required FFT lengths to compute restricted $g^p$}
%     \begin{tabular}{c|c|c|c|c}
%     $\bsfrac{\,p}{n}$ & 5 & 7 & 11 & 13 \\ \hline
%     4 & 262,144 & 2,097,152 & 67,108,864 & 134,217,728 \\
%     5 & 67,108,864 & 1,073,741,824 & 68,719,476,736 & 274,877,906,944
%     \end{tabular}
% \end{center}


\subsection{Finding the Maximum Coefficient}
In order to determine which moduli to perform our FFT in, we first need to obtain an upper bound on all of 
the coefficients of $g ^ p$.

For small problems, we can simply plug in the maximum possible polynomial $g$ into FLINT, compute $g ^ p$, and iterate through the coefficients to get the maximum possible coefficient.
We know this computation will be correct because FLINT uses GMP. However, for larger problems, such as K3 quartic surfaces over $\mathbb{F}_{13}$, FLINT does not finish computing $g ^ p$ in a reasonable amount of time, around 3 hours. So, we need a some method to compute a bound without needing to do the entire computation.

To begin, we need to introduce weak integer compositions:

\begin{defn}
    The weak integer compositions of $n$ into $k$ parts is the set of ordered $k$-length tuples of non-negative integers that add to $n$.
\end{defn}

For example, the weak integer compositions of $2$ into $3$ parts is:
\begin{center}
    $wics(2, 3) = \lbrace (2, 0, 0), (0, 2, 0), (0, 0, 2), (1, 1, 0), (1, 0, 1), (0, 1, 1) \rbrace$
\end{center}

\begin{lem}
    $|wics(n, k)| = \binom{n + k - 1}{k - 1}$
\end{lem}

\begin{proof}
    in stars and bars page on wikipedia
\end{proof}

\begin{thm}
    Let $f$ be a homogeneous polynomial of $F_p[x_1, ..., x_n]$, $g = f ^ {p - 1}$ and $[g]$ a lift of $g$ to the integers. Then, the coefficients of $g ^ k$ are bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ k$
\end{thm}

\begin{proof}
    We use proof by induction. The maximum coefficient of $g^0$ is $1$, which is bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ 0 = 1$.
    
    Let $(d_1, \dots , d_n)$ denote the degree sequence of a term of $g^k$, let $(d'_1, \dots , d'_n)$ denote the degree sequence of a term of $g^{k + 1}$, and let $(a_1, \dots , a_n)$ denote the degree sequence of a term of $g$.

    Consider an arbitrary term of $g^{k + 1}$. To find all terms in the unreduced expansion of $g^k \cdot g$ that contribute to that term, we look at terms of $g^k$ with degree sequences of the form $(d'_1 - a_1, \dots , d'_n - a_n)$. The number of these terms of $g^k$ is bounded above by $|wics(np, n)|$, or $\binom{np + n - 1}{n - 1}$. Using our inductive assumption, the maximum coefficient of $g^k$ is bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ k$, so multiplying each of these by coefficients of $g$, which have a maximum value of $p - 1$, and adding up $\binom{np + n - 1}{n - 1}$ copies of these gives $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ k + 1$, completing our inductive step.
\end{proof}

To choose primes to perform the FFT in, we chose primes that were equal to $k * L + 1$, where $L$ is the length of the FFT, since in order for a $L$-th principal root of unity to exist in $\mathbb{F}_p$, $L$ has to divide $p - 1$

\subsection{Other algorithms}
Many other algorithms are described in [CITE]. In this section we touch on them, and discuss why they
weren't used.

\subsubsection{RMUL and RSQR}
GPU parallelized versions even slower than CPU fps algorithm in OSCAR. (will benchmark later)

\subsubsection{BINA and BINB}
Also even slower than CPU fps algorithm (will also benchmark later)

\subsubsection{MNE}
Note that a basic implementation of MNE actually outperforms FPS for computing $g = f^{p - 1}$. However, 
since this step is already instantaneous compared to computing $g ^ p$, we use FPS because it doesn't require 
the hassle of pregeneration.

The memory consumption of MNE scales terribly with the number of input terms, meaning it isn't exactly suited for computing $g ^ p$. In fact, for the $(n, p) = (4, 5)$ problem, 1294 yottabytes are required to store the multinomial lookup table. This is 100 million times more than the entire internet. So, we cannot use this method. (i must've gotten this computation wrong)

% In order to generate a multinomial coefficient lookup table for $g^p$, we need to compute the most number of terms $g^p$ can have. Letting $n$ be the number of variables of $g$, this turns out to be the number of ways to distribute $n(p - 1)$ balls into $n$ bins, or $T = \binom{n(p - 1) + n - 1}{n - 1}$. 

\subsubsection{SUMS and FPS}
FPS, the more optimized version of SUMS, performs better than FFT at < 10 starting terms. However,
parallelization faces diminishing returns per thread added, to the point where the merge algorithm needed
will take longer than the CPU version. (in theory, I've been too lazy to actually implement it with GPU 
heap)