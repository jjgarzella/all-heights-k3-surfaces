In this section, we explore algorithms for raising multivariate homogeneous polynomials to powers. Specifically, we consider the benefits mass parallelization using the GPU gives.

\subsection{Kronecker Substitution and Homogeneity}
In multivariate polynomial arithmetic, it is commonplace to map a multivariate polynomial to a univariate 
polynomial. This is because a comparison between two degree sequences $(d_1, \dots , d_n)$ of monomials 
$x_1^{d_1} \dots x_n^{d_n}$ is $n$ times slower than comparing two integers. This also allows us to use the vast majority of polynomial powering algorithms, which take in univariate polynomials. One method of mapping a multivariate polynomial to a sparse univariate polynomial is the Kronecker Substitution.

\begin{defn}
    Let $M$ be a non-inclusive upper bound on the degree of any variable of the polynomial
    $f \in R[x_1, \dots, x_n]$. Then, the Kronecker Substitution produces a univariate polynomial $g \in R[z]$ by substituting powers of $z$ in 
    the evaluation of $f$: [cite this]{https://arxiv.org/pdf/1401.6694}

    \begin{center}
        $g(z) = f(z, z^M, z^{M^2}, \dots, z^{M^{n-1}})$
    \end{center}
\end{defn}

\begin{rmk}
    In FLINT, degree sequences of multivariate monomials are bitpacked into unsigned integers. The process of bitpacking an array is a kronecker substitution with $M$ being a power of 2.
\end{rmk}

In the case where our polynomial is homogeneous, we can simply ignore one variable in all of our operations between monomials of the same degree. Because the total degree for each monomial is known, the variable can be recovered. This effectively decreases the number of variables of our polynomial by 1, which plays a large role in dense algorithms, like the FFT.

\subsection{NTT}
The FFT is a very well-known algorithm, with one of its many applications being raising dense univariate polynomials to powers.
Because we are working with integers, we use the Number Theoretic Transform (NTT), its finite field counterpart. We also refer to the NTT with ``multi-modular FFT''.

To begin, we first define the length of an NTT:

\begin{defn}
    Given a NTT from $\mathbb{F}_p^L \rightarrow \mathbb{F}_p^L$, the \textbf{length} of the NTT is $L$.
\end{defn}

A quick overview of the NTT algorithm for polynomial powering is given:

\begin{alg} Inputs: f, p, pow, where f is a dense representation of a 
polynomial, p is a NTT prime, and pow is an integer.
Output: dense representation of $g = f ^ {pow} \mod p$

\begin{enumerate}
    \item Compute the maximum degree of $d = f ^ {pow} \mod p$, and set $L = d + 1$. Pad $f$ with $0$'s to length $L$
    \item Perform an NTT of length $L$ and prime $p$ on $f$ to obtain $f'$.
    \item Raise each element of $f'$ to the $pow$th power, and reduce mod $p$.
    \item Perform an INTT on $f'$ to obtain $g$.
\end{enumerate}

\end{alg}

This algorithm is usually performed multiple times with distinct primes $p$, and the results are combined using the Chinese Remainder Theorem to obtain a result in $\mathbb{Z}$

In many cases, using the Kronecker Substitution to map a multivariate polynomial to a univariate polynomial results in  a sparse univariate polynomial. As a result, dense algorithms like Algorithm 3.4 become inefficient in both time and memory complexity when compared to sparse algorithms. However, the massive throughput of the GPU allows the NTT to be competitive for these cases, $4$-variate homogeneous polynomial powering being one of them.

\subsubsection{NTT Implementation}

We use a simple radix-2, 1-dimensional NTT for our polynomial powering algorithm. Because we're using radix-2, our length $L$ is always a power of $2$. For each NTT we perform, we find primes $p$ that satisfy $p = 1 \mod L$, compute primitive $L$th roots of unity for each $p$, and $L^{-1} \mod p$. We cache all of these, so that they can be used again for similar problems, where $L$ and the set of primes are the same.

We choose to use integers in our computations, as opposed to floats. The NTT becomes memory intensive very quickly, so the added precision of integers is a tradeoff we take at the cost of very slightly slower computations.

Additionally, we used fixed-width integers, as opposed to arbitrary-precision integers since GPU SIMT architectures are optimized for operations on fixed-width types. Fixed-width float types beyond 32 and 64 bits typically don't have hardware support, the main benefit from using floats, another reason we choose to use integers over floats.

As the length of the NTT increases, the primes we perform the NTT in increases as well, and we need to start worrying about overflowing our integer type. The most memory-intensive operation the NTT requires is powering mod $p$, which can be reduced to iterative multiplication mod $p$. So, for each prime $p$, we find the smallest unsigned integer type $T$ that can represent $p^2$, and perform our NTT using $T$.

When the memory required by the NTT reaches the point where the GPU can't perform the Cooley-Tukey butterfly in its own memory, we sacrifice performance by moving each vector back to RAM to perform the butterfly, and transferring each vector back to the GPU for the operations that can be done in-place.

The Julia language provides tools for us to implement our NTT. Using the BitIntegers.jl package, fixed-width integer arithmetic gets compiled down to an intermediate representation using LLVM, and the CUDA.jl package invokes the nvidia compiler to generate PTX assembly from this intermediate representation.

\subsubsection{Selecting primes}

Because we are working in $\mathbb{Z}$, we need to convert the result from our multi-modular NTT over $\mathbb{F}_p$ to $\mathbb{Z}$. To do so, we can either select a prime bigger than the maximum possible resulting coefficient of our result $M$, or select multiple primes $p_1,\dots , p_n$ that satisfy $\prod_{i=0}^{n} p_i > M$, and use the Chinese Remainder Theorem for integers to get a result in $\mathbb{Z}$.

This poses the question of finding the maximum coefficient of our result $M$. 

\begin{defn}
    Given a basis $(x^{I_1}, \dots, x^{I_n})$, where $I_i$ are distinct degree sequences of equal length, and a prime field $\mathbb{F}_p$, the \textbf{maximum polynomial} is $(p - 1)(x^{I_1} + \cdots + x^{I_n})$.
\end{defn}

For small problems, we can simply plug in the maximum possible polynomial $g$ into FLINT, compute $g ^ p$, and linearly iterate through the coefficients to get the maximum possible coefficient.
We know this computation will be correct because FLINT uses GMP. However, for larger problems, such as raising a 4-variate polynomial of homogeneous degree $52$ to the $13$th power (this comes from computing the quasi-F-split height of a quartic $K_3$ surface over $\mathbb{F}_{13}$), FLINT does not finish the computation in a reasonable amount of time, around 3 hours.

We present a method to quickly obtain an upper bound for the case of raising a homogeneous multivariate polynomial over $\mathbb{F}_p[x_1, \dots , x_k]$ to a power. To begin, we need to introduce weak integer compositions:

\begin{defn}
    The weak integer compositions of $n$ into $k$ parts is the set of ordered $k$-length tuples of non-negative integers that add to $n$.
\end{defn}

For example, the weak integer compositions of $2$ into $3$ parts is:
\begin{center}
    $wics(2, 3) = \lbrace (2, 0, 0), (0, 2, 0), (0, 0, 2), (1, 1, 0), (1, 0, 1), (0, 1, 1) \rbrace$
\end{center}

\begin{lem}
    $|wics(n, k)| = \binom{n + k - 1}{k - 1}$
\end{lem}

\begin{proof}
    in stars and bars page on wikipedia
\end{proof}

\begin{thm}
    Let $f$ be a homogeneous polynomial of $\mathbb{F}_p[x_1, ..., x_n]$, $g = f ^ {p - 1}$ and $[g]$ a lift of $g$ to the integers. Then, the coefficients of $g ^ k$ are bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ k$
\end{thm}

\begin{proof}
    We induct on $k$. The maximum coefficient of $g^0$ is $1$, which is bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ 0 = 1$.
    
    Let $(d_1, \dots , d_n)$ denote the degree sequence of a term of $g^k$, let $(d'_1, \dots , d'_n)$ denote the degree sequence of a term of $g^{k + 1}$, and let $(a_1, \dots , a_n)$ denote the degree sequence of a term of $g$.

    Consider an arbitrary term of $g^{k + 1}$. To find all terms in the unreduced expansion of $g^k \cdot g$ that contribute to that term, we look at terms of $g^k$ with degree sequences of the form $(d'_1 - a_1, \dots , d'_n - a_n)$. The number of these terms of $g^k$ is bounded above by $|wics(np, n)|$, or $\binom{np + n - 1}{n - 1}$. Using our inductive assumption, the maximum coefficient of $g^k$ is bounded above by $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ k$, so multiplying each of these by coefficients of $g$, which have a maximum value of $p - 1$, and adding up $\binom{np + n - 1}{n - 1}$ copies of these gives $((p - 1) \cdot \binom{np + n - 1}{n - 1}) ^ {k + 1}$, completing our inductive step.
\end{proof}

This formula provides a quick way to compute a relatively accurate upper bound for our problem. To find the exact maximum coefficient of raising a maximum polynomial $g ^ p$, we simply use Algorithm 3.4 with primes that multiply past our upper bound, build the result in $\mathbb{Z}$ using Chinese Remainder Theorem, and iterate through the coefficients of $g^p$ to find the actual maximum coefficient.


% To determine the size of our FFT, we need to compute the largest possible degree that the Kronecker 
% Substitution can map a monomial of $g^p$ to. Let $f \in R[x_1, \dots, x_n]$ be homogeneous with degree $d$. Then, 
% $(f^{p-1})^p$ is homogeneous with degree $D = dp(p - 1)$. Then, by Definition 3.1, we can select an upper bound 
% of $M = D + 1$, and the maximum degree the Kronecker Substitution will be able to map to is $D*M^{n - 1}$. But 
% if we ignore one variable of $f$ due to the homogeneous property, we get a maximum degree of $D*M^{n - 2}$. 
% Because we use a radix-2 FFT, we find the next power of 2 after $D*M^{n - 2} + 1$, the $+1$ coming from a 
% $k$-length FFT representing a $k-1$ degree polynomial.

% Below is a table of FFT lengths needed to compute $g^p$:

% Because we are doing a FFT with integers, we 

% \begin{center}
%     \textbf{Required FFT lengths to compute $g^p$}
%     \begin{tabular}{c|c|c|c|c}
%     $\bsfrac{\,p}{n}$ & 5 & 7 & 11 & 13 \\ \hline
%     4 & 1,048,576 & 8,388,608 & 134,217,728 & 268,435,456 \\
%     5 & 134,217,728 & 2,147,483,648 & 137,438,953,472 & 549,755,813,888
%     \end{tabular}
% \end{center}    

% To make computing $\Delta_1(f^{p-1})$ even faster, we look for ways to reduce the FFT size. One such way is by imposing restrictions on the space of possible monomials. Consider the restriction where we remove all terms containing only one variable raised to the $n$-th power from the basis of monomials of $f$.

% [Explanation on how the restriction affects kroneckersubstitution]

% Below is a table of FFT lenghts needed to compute the restricted $g^p$:


% \begin{center}
%     \textbf{Required FFT lengths to compute restricted $g^p$}
%     \begin{tabular}{c|c|c|c|c}
%     $\bsfrac{\,p}{n}$ & 5 & 7 & 11 & 13 \\ \hline
%     4 & 262,144 & 2,097,152 & 67,108,864 & 134,217,728 \\
%     5 & 67,108,864 & 1,073,741,824 & 68,719,476,736 & 274,877,906,944
%     \end{tabular}
% \end{center}


\subsection{Other algorithms}
Many other algorithms are described in [CITE]. They compare performance in sparse and dense cases. In this section we consider whether or not they benefit from massive parallelization.

\subsubsection{RMUL and RSQR}
These algorithms are bottlenecked by a sort, which does benefit from parallelization, but not by much. We tried implementing the sorting algorithm from [CITE], but couldn't reproduce the results.

\subsubsection{BINA and BINB}
BINA and BINB both call RMUL, which again, doesn't benefit much from parallelization.

\subsubsection{MNE}
MNE again, requires a sort, but isn't dominated by the sort. The computation of each multinomial coefficient is greatly improved by parallelization, but again, is only feasible for small problems.

% The memory consumption of MNE scales terribly with the number of input terms, meaning it isn't exactly suited for computing $g ^ p$. In fact, for in computing $\Delta_1$ for the problem of , 1294 yottabytes are required to store the multinomial lookup table. This is 100 million times more than the entire internet. So, we cannot use this method. (i must've gotten this computation wrong)

% In order to generate a multinomial coefficient lookup table for $g^p$, we need to compute the most number of terms $g^p$ can have. Letting $n$ be the number of variables of $g$, this turns out to be the number of ways to distribute $n(p - 1)$ balls into $n$ bins, or $T = \binom{n(p - 1) + n - 1}{n - 1}$. 

\subsubsection{SUMS and FPS}
The parallelization of FPS is discussed in [CITE], but the implementation uses a lock, as well as a heap data structure, both of which aren't easily compatible with the GPU.